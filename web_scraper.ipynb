{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web_scraper.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kethlyncampos/webscraper/blob/main/web_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uoivF9x1NIjU",
        "outputId": "461e0020-c47b-4b2f-cc55-395d364e6034"
      },
      "source": [
        "!apt update\n",
        "!apt install chromium-chromedriver\n",
        "!pip install selenium\n",
        "!pip install requests\n",
        "!pip install iso8601"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\u001b[0m\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,224 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,868 kB]\n",
            "Fetched 5,343 kB in 3s (1,795 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "40 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (95.0.4638.69-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (4.1.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.19.0)\n",
            "Collecting urllib3[secure]~=1.26\n",
            "  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.2.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (21.0.0)\n",
            "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (36.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.21)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.25.11\n",
            "    Uninstalling urllib3-1.25.11:\n",
            "      Successfully uninstalled urllib3-1.25.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.7 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed urllib3-1.26.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.7\n",
            "    Uninstalling urllib3-1.26.7:\n",
            "      Successfully uninstalled urllib3-1.26.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "selenium 4.1.0 requires urllib3[secure]~=1.26, but you have urllib3 1.25.11 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: iso8601 in /usr/local/lib/python3.7/dist-packages (1.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMAJnCDUB6HD"
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from time import sleep\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "import iso8601\n",
        "from dateutil import tz\n",
        "from google.colab import drive\n",
        "from selenium.webdriver.common.by import By\n",
        "import re\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SmJj6dEY6hH"
      },
      "source": [
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument(\"--disable-notifications\")\n",
        "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.125 Safari/537.36\")\n",
        "browser = webdriver.Chrome(options=options)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO3L-sHDhZCT"
      },
      "source": [
        "def req_yahoo(url):\n",
        "  browser.get(url)\n",
        "  lastHeight = browser.execute_script(\"return document.body.scrollHeight\")\n",
        "  while True:\n",
        "      browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "      sleep(5)\n",
        "      newHeight = browser.execute_script(\"return document.body.scrollHeight\")\n",
        "      if newHeight == lastHeight:\n",
        "          break\n",
        "      lastHeight = newHeight\n",
        "  return BeautifulSoup(browser.page_source, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utFooPXXsRQB"
      },
      "source": [
        "def req_infomoney(url):\n",
        "  try:\n",
        "    browser.get(url)\n",
        "    browser.implicitly_wait(10)\n",
        "    browser.maximize_window()\n",
        "    alert = browser.switch_to.active_element.click\n",
        "    infinite = browser.find_element(By.ID, 'infinite-handle')\n",
        "    browser.execute_script(\"arguments[0].click();\", infinite)\n",
        "    count = 40\n",
        "    while(count > 0):\n",
        "      browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "      sleep(5)\n",
        "      browser.execute_script(\"arguments[0].click();\", infinite)\n",
        "      newHeight = browser.execute_script(\"return document.body.scrollHeight\")\n",
        "      lastHeight = newHeight\n",
        "      count-=1\n",
        "  except:\n",
        "    return False\n",
        "  return BeautifulSoup(browser.page_source, 'html.parser')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8X31gw356cO"
      },
      "source": [
        "def convert_timezone(date_time):\n",
        "  sp = tz.gettz('America/Sao_Paulo')\n",
        "  new_date = date_time.replace(tzinfo=pytz.utc)\n",
        "  new_date = new_date.astimezone(sp)\n",
        "  new_date = new_date.strftime('%Y-%m-%d %H:%M:%S')\n",
        "  return new_date"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6G7G5KSeJdx"
      },
      "source": [
        "def trata_string(data):\n",
        "  data = re.sub(r'[\\t\\n ]+', ' ', data)\n",
        "  data = re.sub(r'(?s)<figure.*?</figure>', ' ', data)\n",
        "  return data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6u7-BIWumf_"
      },
      "source": [
        "page = req_yahoo('https://br.yahoo.com/topics/bolsa-de-valores/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eWfkHXRhXae"
      },
      "source": [
        "links = page.find_all('a', attrs={'class':'js-content-viewer','class':'rapidnofollow'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_1038r9DLOs"
      },
      "source": [
        "lista_url = []\n",
        "for link in links:\n",
        "  aux = link['href']\n",
        "  if 'http' not in aux:\n",
        "    aux = 'https://br.yahoo.com' + aux\n",
        "  if 'noticias-do-dia-' not in aux:\n",
        "    lista_url.append(aux)\n",
        "lista_url = set(lista_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b65ylHepm5TH"
      },
      "source": [
        "title, description, author, publication_date, collect_date = \"\", \"\", \"\", \"\", \"\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-fGUwK2o6wM"
      },
      "source": [
        "noticias = []\n",
        "\n",
        "for i in lista_url:\n",
        "  temp = req_yahoo(i)\n",
        "  title = temp.find('h1', attrs={'data-test-locator':'headline'}).text\n",
        "  author = temp.find('span', attrs={'class':'caas-author-byline-collapse'}).text\n",
        "  collect_date = convert_timezone(datetime.now())\n",
        "  publication_date = convert_timezone(iso8601.parse_date(temp.find('time')['datetime']))\n",
        "  description = temp.find('div', attrs={'class':'caas-body'}).text\n",
        "  noticias.append(['Yahoo Finanças',title, description, author, publication_date, collect_date, i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78MIEOvJj-QT"
      },
      "source": [
        "dataset = pd.DataFrame(noticias,columns=['Fonte', 'Título', 'Descrição', 'Autor', 'Data/Hora de Publicação', 'Data/Hora de Coleta', 'URL'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xURXSqAzPHaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4460c374-f7d3-4a29-8a23-5dc865a129f2"
      },
      "source": [
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1DifIwsP2BM"
      },
      "source": [
        "dataset.drop_duplicates(subset=['Descrição'], inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3uNlUoWX0aS"
      },
      "source": [
        "dataset.reset_index(drop = True, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoOJcdBJwEwC"
      },
      "source": [
        "dataset.to_csv('/content/gdrive/MyDrive/news_yahoo.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvip81rwU8Lv",
        "outputId": "63194e53-a46c-436e-9b88-f1a020e2fd28"
      },
      "source": [
        "page = req_infomoney('https://www.infomoney.com.br/mercados/')\n",
        "if not page:\n",
        "  print(\"Recompile o código, aguarde um momento e tente novamente!\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recompile o código, aguarde um momento e tente novamente!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXXdrYoxmixz"
      },
      "source": [
        "links = page.find_all(class_=\"hl-title\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LBjWJ1joKx0"
      },
      "source": [
        "lista_url = []\n",
        "for j in links:\n",
        "  aux = j.find('a')\n",
        "  if(aux):\n",
        "    if \"stock-pickers\" not in aux['href']:\n",
        "      lista_url.append(aux['href'])\n",
        "lista_url = set(lista_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55wJO_GuQ1zq"
      },
      "source": [
        "noticias = []\n",
        "subtitle = \"\"\n",
        "for k in lista_url:\n",
        "  response = requests.get(k)\n",
        "  temp = BeautifulSoup(response.content, 'html.parser')\n",
        "  title = temp.find('h1', attrs={'class': 'page-title-1'})\n",
        "  if title: # se não houver título, a página é do tipo cotações e possui apenas as informações sobre a empresa\n",
        "    title = title.text\n",
        "    subtitle = trata_string(temp.find('p', attrs={'class': 'article-lead'}).text)\n",
        "    author = temp.find('span', attrs={'class':'author-name'})\n",
        "    if author:\n",
        "      author = trata_string(author.find('a').text) # se não houver autor, a página é do tipo guias\n",
        "      collect_date = convert_timezone(datetime.now())\n",
        "      publication_date = iso8601.parse_date(temp.find('time', attrs={'class':'entry-date'})['datetime']).strftime('%Y-%m-%d %H:%M:%S')\n",
        "      description = trata_string(temp.find('div', attrs={'class':'article-content'}).text)\n",
        "      noticias.append(['Infomoney',title, subtitle, description, author, publication_date, collect_date, k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqhIf3qXUW1y"
      },
      "source": [
        "dataset2 = pd.DataFrame(noticias,columns=['Fonte', 'Título', 'Subtítulo','Descrição', 'Autor', 'Data/Hora de Publicação', 'Data/Hora de Coleta', 'URL'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skZxU94GwPdx"
      },
      "source": [
        "dataset2.drop_duplicates(subset=['Descrição'], inplace = True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApAnNl2dwo2s"
      },
      "source": [
        "dataset2.reset_index(drop = True, inplace = True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiEOiqrQraxl"
      },
      "source": [
        "dataset2.to_csv('/content/gdrive/MyDrive/news_infomoney.csv')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYOcU3upv_GA"
      },
      "source": [
        "dataset2"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}