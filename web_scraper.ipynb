{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web_scraper.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP7+JE7OW/jJinkoAJdcgAP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kethlyncampos/webscraper/blob/main/web_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ2KkZGzSrnk"
      },
      "source": [
        "!apt update\n",
        "!apt install chromium-chromedriver\n",
        "!pip install selenium\n",
        "!pip install requests\n",
        "!pip install iso8601"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJBceqNAS7Sw"
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from time import sleep\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "import iso8601\n",
        "from dateutil import tz\n",
        "from google.colab import drive\n",
        "from selenium.webdriver.common.by import By\n",
        "import re\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlZObRxMTZl7"
      },
      "source": [
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bebDQUaTnhu"
      },
      "source": [
        "yahoo = pd.read_csv('/content/gdrive/MyDrive/news_yahoo.csv')\n",
        "infomoney = pd.read_csv('/content/gdrive/MyDrive/news_infomoney.csv', lineterminator='\\n')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxuD3W8_Tsqu"
      },
      "source": [
        "comp_yahoo = []\n",
        "comp_infomoney = []\n",
        "\n",
        "for c in yahoo['URL']:\n",
        "  comp_yahoo.append(c)\n",
        "\n",
        "for c in infomoney['URL']:\n",
        "  comp_infomoney.append(c)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvLBTaMMS_VR"
      },
      "source": [
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument(\"--disable-notifications\")\n",
        "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.125 Safari/537.36\")\n",
        "browser = webdriver.Chrome(options=options)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYq9ahFKTDAZ"
      },
      "source": [
        "def req_yahoo(url):\n",
        "  browser.get(url)\n",
        "  scrollar()\n",
        "  links = browser.find_elements(By.CSS_SELECTOR, 'a.js-content-viewer.rapidnofollow')\n",
        "  noticias = []\n",
        "\n",
        "  for link in links:\n",
        "    if (('https://br.yahoo.com/news/' not in link.get_attribute('href')) and (link.get_attribute('href') not in comp_yahoo)):\n",
        "      browser.execute_script(\"arguments[0].click();\", link)\n",
        "      scrollar()\n",
        "      WebDriverWait(browser, 20).until(EC.presence_of_element_located((By.TAG_NAME, \"h1\")))\n",
        "      temp = BeautifulSoup(browser.page_source, 'html.parser')\n",
        "      title = temp.find('h1', attrs={'data-test-locator':'headline'}).text\n",
        "      author = temp.find('span', attrs={'class':'caas-author-byline-collapse'}).text\n",
        "      collect_date = convert_timezone(datetime.now())\n",
        "      publication_date = convert_timezone(iso8601.parse_date(temp.find('time')['datetime']))\n",
        "      description = temp.find('div', attrs={'class':'caas-body'})\n",
        "      try:\n",
        "        description.figure.decompose()\n",
        "        description = description.text\n",
        "      except:\n",
        "        description = description.text\n",
        "      noticias.append(['Yahoo Finanças',title, description, author, publication_date, collect_date, browser.current_url])\n",
        "      browser.back()\n",
        "      sleep(5)\n",
        "\n",
        "  return noticias"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uy2uP2Lc6mo"
      },
      "source": [
        "def req_infomoney(url):\n",
        "  browser.get(url)\n",
        "  #browser.implicitly_wait(10)\n",
        "  browser.maximize_window()\n",
        "  alert = browser.switch_to.active_element.click\n",
        "  infinite = browser.find_element(By.ID, 'infinite-handle')\n",
        "  browser.execute_script(\"arguments[0].click();\", infinite)\n",
        "  count = 40\n",
        "  while(count > 0):\n",
        "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    WebDriverWait(browser, 20).until(EC.presence_of_element_located((By.ID, \"infinite-handle\")))\n",
        "    browser.execute_script(\"arguments[0].click();\", infinite)\n",
        "    newHeight = browser.execute_script(\"return document.body.scrollHeight\")\n",
        "    lastHeight = newHeight\n",
        "    count-=1\n",
        "  return BeautifulSoup(browser.page_source, 'html.parser')"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpi-WFnFTGi6"
      },
      "source": [
        "def scrollar():\n",
        "  lastHeight = browser.execute_script(\"return document.body.scrollHeight\")\n",
        "  while True:\n",
        "      browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "      sleep(5)\n",
        "      newHeight = browser.execute_script(\"return document.body.scrollHeight\")\n",
        "      if newHeight == lastHeight:\n",
        "          break\n",
        "      lastHeight = newHeight\n",
        "  return"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86_FH_jcTLSV"
      },
      "source": [
        "def convert_timezone(date_time):\n",
        "  sp = tz.gettz('America/Sao_Paulo')\n",
        "  new_date = date_time.replace(tzinfo=pytz.utc)\n",
        "  new_date = new_date.astimezone(sp)\n",
        "  new_date = new_date.strftime('%Y-%m-%d %H:%M:%S')\n",
        "  return new_date"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYtWcU_JTNv8"
      },
      "source": [
        "def trata_string(data):\n",
        "  data = re.sub(r'[\\t\\n ]+', ' ', data)\n",
        "  data = re.sub(r'(?s)<figure.*?</figure>', ' ', data)\n",
        "  return data"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHdfAK0iTPBH"
      },
      "source": [
        "array_noticias = req_yahoo('https://br.yahoo.com/topics/bolsa-de-valores/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-OQ18uMTfCZ"
      },
      "source": [
        "dataset_temp = pd.DataFrame(array_noticias,columns=['Fonte', 'Título', 'Descrição', 'Autor', 'Data/Hora de Publicação', 'Data/Hora de Coleta', 'URL'])"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4HcTrIx3Bd"
      },
      "source": [
        "if dataset_temp > 0:\n",
        "  dataset_temp.drop_duplicates(subset=['Descrição'], inplace = True)\n",
        "  dataset_temp.reset_index(drop = True, inplace = True)\n",
        "  yahoo = pd.concat([dataset_temp,yahoo],ignore_index=True)\n",
        "  yahoo.to_csv('/content/gdrive/MyDrive/news_yahoo.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCN98JB5UMHl"
      },
      "source": [
        "page = req_infomoney('https://www.infomoney.com.br/mercados/')"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajTFjA77UPZN"
      },
      "source": [
        "links = page.find_all(class_=\"hl-title\")"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-GbKci5URlQ"
      },
      "source": [
        "lista_url = []\n",
        "for j in links:\n",
        "  aux = j.find('a')\n",
        "  if(aux):\n",
        "    if \"stock-pickers\" not in aux['href']:\n",
        "      lista_url.append(aux['href'])\n",
        "lista_url = set(lista_url)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7UkIMUiUZ1I"
      },
      "source": [
        "noticias = []\n",
        "subtitle = \"\"\n",
        "for k in lista_url:\n",
        "  if k not in comp_infomoney:\n",
        "    response = requests.get(k)\n",
        "    temp = BeautifulSoup(response.content, 'html.parser')\n",
        "    title = temp.find('h1', attrs={'class': 'page-title-1'})\n",
        "    if title: # se não houver título, a página é do tipo cotações e possui apenas as informações sobre a empresa\n",
        "      title = title.text\n",
        "      subtitle = trata_string(temp.find('p', attrs={'class': 'article-lead'}).text)\n",
        "      author = temp.find('span', attrs={'class':'author-name'})\n",
        "      if author:\n",
        "        author = trata_string(author.find('a').text) # se não houver autor, a página é do tipo guias\n",
        "        collect_date = convert_timezone(datetime.now())\n",
        "        publication_date = iso8601.parse_date(temp.find('time', attrs={'class':'entry-date'})['datetime']).strftime('%Y-%m-%d %H:%M:%S')\n",
        "        description = temp.find('div', attrs={'class':'article-content'})\n",
        "        try:\n",
        "          description.figure.decompose()\n",
        "          description = description.text\n",
        "        except:\n",
        "          description = description.text\n",
        "        description = trata_string(description)\n",
        "        noticias.append(['Infomoney',title, subtitle, description, author, publication_date, collect_date, k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6wxon6ZUb_w"
      },
      "source": [
        "dataset_temp = pd.DataFrame(noticias,columns=['Fonte', 'Título', 'Subtítulo','Descrição', 'Autor', 'Data/Hora de Publicação', 'Data/Hora de Coleta', 'URL'])"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V93b35qCUdqP"
      },
      "source": [
        "if len(dataset_temp > 0):\n",
        "  dataset_temp.drop_duplicates(subset=['Descrição'], inplace = True)\n",
        "  dataset_temp.reset_index(drop = True, inplace = True)\n",
        "  infomoney = pd.concat([dataset_temp, infomoney])\n",
        "  infomoney.to_csv('/content/gdrive/MyDrive/news_infomoney.csv')"
      ],
      "execution_count": 115,
      "outputs": []
    }
  ]
}